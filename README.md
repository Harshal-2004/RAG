# ğŸ“š Ask PDF - RAG Chatbot
A **Retrieval-Augmented Generation (RAG) chatbot** built with **Streamlit**, **LangChain**, **Groq API**, **FAISS**, and **HuggingFace embeddings**. This app allows you to **chat with your PDFs** and get context-aware answers.

## ğŸš€ Features
- ğŸ“„ Query any PDF stored in the `vectorstores/` folder  
- âš¡ Powered by **Groqâ€™s Llama-3-8B** for fast responses  
- ğŸ” Uses **FAISS** vector database for efficient retrieval  
- ğŸ§  Embeddings with HuggingFace `all-MiniLM-L12-v2`  
- ğŸ¨ ChatGPT-like interface with **Streamlit**  
- âŒ Hallucination filter (rejects irrelevant answers)  

## ğŸ› ï¸ Tech Stack
- [Python](https://www.python.org/)  
- [Streamlit](https://streamlit.io/)  
- [LangChain](https://www.langchain.com/)  
- [Groq API](https://groq.com/)  
- [FAISS](https://faiss.ai/)  
- [HuggingFace Transformers](https://huggingface.co/)  

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ data/ # Raw PDF files (before embedding)
â”œâ”€â”€ vectorstores/ # Precomputed FAISS vector databases
â”œâ”€â”€ build_vectorstore.py # Script to create embeddings from PDFs
â”œâ”€â”€ main.py / app.py # Streamlit chatbot app
â”œâ”€â”€ phase_1.py,2.py,3.py # Experimentation files
â”œâ”€â”€ .env # API keys (ignored in git)
â”œâ”€â”€ .env.example # Example environment file
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Project documentation



## âš™ï¸ Setup & Installation
### 1ï¸âƒ£ Clone Repo
```bash
git clone https://github.com/Harshal-2004/RAG.git
cd <your-repo>
2ï¸âƒ£ Install Requirements
pip install -r requirements.txt

3ï¸âƒ£ Setup Environment Variables

Create a .env file (not tracked in git):
GROQ_API_KEY=your_groq_api_key_here
4ï¸âƒ£ Build Vectorstores (from PDFs)
python build_vectorstore.py

5ï¸âƒ£ Run the Streamlit App
streamlit run main.py


ğŸ¯ Usage

Select a PDF (vectorstore) from dropdown.

Ask a question in the chat input.

Get context-based answers directly from the PDF.
